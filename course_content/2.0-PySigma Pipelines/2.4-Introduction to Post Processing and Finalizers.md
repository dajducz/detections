# 2.4 :: Introduction to Post Processing and Finalizers

In an assembly line you will have many steps that are performed that will, along the way, transform some simple materials into a fully refined product that is ready to present to a customer. As one of the final steps on every assembly line you will have a function that packages and prepares the product and essentially "makes it pretty.”

In the PySigma world of pipelines, this is called query post processing and output finalization. A Sigma rule is a raw unrefined material that is passed to a converter with the intention of generating a query that can be run in a SIEM. In our specific context - we are looking to convert a Sigma rule into the format that Splunk uses for automated scheduled searches: `savedsearches.conf`.

In a previous example, I had you execute the following pipeline without explaining much about what was going on:

```yaml
# Global win eventlog index
transformations:
    - id: index_condition
      type: add_condition
      conditions:
        index: winevent
      rule_conditions:
        - type: logsource
          product: windows

postprocessing:
    - type: template
      template: |+
            [{{ rule.id }}]
            search = {{ query }} | eval rule="{{ rule.id }}", title="{{ rule.title }}" | collect index=notable_events
            description = “{{ rule.description }}”

finalizers:
    - type: concat
      prefix: |
            [default]
            dispatch.earliest_time = -30d
            dispatch.latest_time = now
            enableSched = 1
            cron_schedule = */15 * * * *
            allow_skew = 5m

```

We’ve already covered the `transformations:` section, so now it is time to discuss `postprocessing:` and `finalizers:`.

*As a quick note before we continue: post-processing is fully supported by SigmaCLI, but for sigconverter.io, you will need to use their beta version. Simply visit `beta.sigconverter.io` instead but accept that there may be some bugs.*

The goal of post-processing and finalizers is to prepare the final product of the transformation: a fully written `savedsearches.conf` file that can be published to your Splunk instance. To do this, the transformation pipeline may follow this workflow:

**[Sigma Rule] → (log source pipeline) → (backend) → (post-processing pipeline) → (finalizer pipeline) → [savedsearches.conf file]**

To explain in more depth:

1. You start with a raw Sigma rule copy/pasted directly from some blog.
2. The Sigma rule will be transformed in such a way that the fields and content of that Sigma rule will be able to be applied to the logs you have using a log source pipeline.
3. The backend will take that transformed content and convert it into the language that your SIEM understands (SPL in our case).
4. The post-processing pipeline will package that SPL in the exact format you want allowing you to define how metadata such as rule titles and descriptions are presented to the SIEM.
5. The finalizer pipeline will apply finishing touches such as default `savedsearches.conf` configurations.
6. Your output will be a fully functional and ready-to-go `savedsearches.conf` file.

To further illustrate this, before I explain how this works, let us revisit the work we did previously. Given a Sigma rule from the PowerShell rules directory and the pipeline we used earlier, we can now demonstrate what this looks like in `savedsearches.conf` format. We glossed over this quickly before - but now that we understand transformations we can dig deeper.

Using beta.sigconverter.io, let’s look at the following Sigma rule and pipeline:

Sigma Rule:

```yaml
title: Silence.EDA Detection
id: 3ceb2083-a27f-449a-be33-14ec1b7cc973
status: test
description: Detects Silence EmpireDNSAgent as described in the Group-IP report
references:
    - https://www.group-ib.com/resources/threat-research/silence_2.0.going_global.pdf
author: Alina Stepchenkova, Group-IB, oscd.community
date: 2019-11-01
modified: 2023-04-03
tags:
    - attack.execution
    - attack.t1059.001
    - attack.command-and-control
    - attack.t1071.004
    - attack.t1572
    - attack.impact
    - attack.t1529
    - attack.g0091
    - attack.s0363
logsource:
    product: windows
    category: ps_script
    definition: 'Requirements: Script Block Logging must be enabled'
detection:
    empire:
        # better to randomise the order
        ScriptBlockText|contains|all:
            - 'System.Diagnostics.Process'
            - 'Stop-Computer'
            - 'Restart-Computer'
            - 'Exception in execution'
            - '$cmdargs'
            - 'Close-Dnscat2Tunnel'
    dnscat:
        # better to randomise the order
        ScriptBlockText|contains|all:
            - 'set type=$LookupType`nserver'
            - '$Command | nslookup 2>&1 | Out-String'
            - 'New-RandomDNSField'
            - '[Convert]::ToString($SYNOptions, 16)'
            - '$Session.Dead = $True'
            - '$Session["Driver"] -eq'
    condition: empire and dnscat
falsepositives:
    - Unknown
level: critical
```

Pipeline:

```yaml
# Global win eventlog index
transformations:
    - id: index_condition
      type: add_condition
      conditions:
        index: winevent
      rule_conditions:
        - type: logsource
          product: windows

postprocessing:
    - type: template
      template: |+
            [{{ rule.id }}]
            search = {{ query }} | eval rule="{{ rule.id }}", title="{{ rule.title }}" | collect index=notable_events
            description = “{{ rule.description }}”

finalizers:
    - type: concat
      prefix: |
            [default]
            dispatch.earliest_time = -30d
            dispatch.latest_time = now
            enableSched = 1
            cron_schedule = */15 * * * *
            allow_skew = 5m

```

The output of this looks like this:

![](https://github.com/The-Taggart-Institute/detection-with-sigma/blob/main/Images/finalizer%2Bpostprocessing.png)

```
[default]
dispatch.earliest_time = -30d
dispatch.latest_time = now
enableSched = 1
cron_schedule = */15 * * * *
allow_skew = 5m
[3ceb2083-a27f-449a-be33-14ec1b7cc973]
search = index="winevent" ScriptBlockText="*System.Diagnostics.Process*" ScriptBlockText="*Stop-Computer*" ScriptBlockText="*Restart-Computer*" ScriptBlockText="*Exception in execution*" ScriptBlockText="*$cmdargs*" ScriptBlockText="*Close-Dnscat2Tunnel*" ScriptBlockText="*set type=$LookupType`nserver*" ScriptBlockText="*$Command | nslookup 2>&1 | Out-String*" ScriptBlockText="*New-RandomDNSField*" ScriptBlockText="*[Convert]::ToString($SYNOptions, 16)*" ScriptBlockText="*$Session.Dead = $True*" ScriptBlockText="*$Session[\"Driver\"] -eq*" | eval rule="3ceb2083-a27f-449a-be33-14ec1b7cc973", title="Silence.EDA Detection" | collect index=notable_events
description = "Detects Silence EmpireDNSAgent as described in the Group-IP report"
```

If you look at the `search = ` section, we can see that the log source pipeline properly injected the `index=”winevent”` stanza and that our backend converted the query into proper SPL. That is exactly what we expect, but there are a few more things happening here because of the post-processing and finalizers elements. Still looking at the `search = ` section, we see that there are some elements appended to our search:

`| eval rule="3ceb2083-a27f-449a-be33-14ec1b7cc973", title="Silence.EDA Detection" | collect index=notable_events`

Then wrapped around the `search = ` we will see the id of the sigma rule captured in block brackets and the description field explicitly stated.

The `postprocessing:` canto of the pipeline is doing this to transform a basic Sigma-to-SPL conversion into the acceptable format used by Splunk’s savedsearches.conf structure. When you previously converted many rules with this pipeline, you saw that each rule generated a block starting with the id and was followed by the search and description. Each subsequently converted rule would just be appended to this list in this format.

The `finalizers:` canto is then prepended to the fully converted object after postprocessing is done. In this example we are using that to define the default conditions for each search such as the search window, the cron schedule, and the automatic skew calculation conditions.

